Analysis:
Analyser, Tokenizer, Token Filter, Character Filter

Used by:
Query, Mapping parameter, Index setting

Tokens are keywords that can be searched/indexed
Analyser are provide to parse and analise different languages (PT-BR, etc)

Reader -> Tokenizer(Break the sentence in tokens and mantain the order id) -> Token Filter -> Token

Stop Words are removed, like A, The, On, etc...
Tokens are always in lower case

Command for bulk load
curl -H "Content-Type: application/json" -XPOST "localhost:9200/bank/_bulk?pretty&refresh" --data-binary "@accounts.json"
curl "localhost:9200/_cat/indices?v"

Cluster
 -Nodes
  -Shards / Replica
  -Shards / Replica

How to see it:
http://localhost:9200/_cat/indices?v&pretty

Filters are cached, it's a very good practice.
When we user "query" we are calling the end-point _search with BODY, yep, body in a GET, the REST doesn't say
nothing about it, so this is how it is.